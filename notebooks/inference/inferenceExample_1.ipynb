{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/homes/a/alazar/acorn/gnn4itk_cf/core/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import gnn4itk_cf.core\n",
    "print(gnn4itk_cf.core.__file__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import yaml\n",
    "from itertools import chain, product, combinations\n",
    "import torch\n",
    "\n",
    "from time import time as tt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from gnn4itk_cf.core.infer_stage import infer\n",
    "from gnn4itk_cf.core.eval_stage import evaluate\n",
    "\n",
    "from gnn4itk_cf.stages.data_reading.models.trackml_utils import *\n",
    "\n",
    "from gnn4itk_cf.stages.data_reading.data_reading_stage import EventReader\n",
    "from gnn4itk_cf.stages.data_reading.models.trackml_reader import TrackMLReader\n",
    "\n",
    "from gnn4itk_cf.stages.graph_construction.models.metric_learning import MetricLearning\n",
    "from gnn4itk_cf.stages.edge_classifier.models.filter import Filter\n",
    "from gnn4itk_cf.stages.edge_classifier import InteractionGNN\n",
    "\n",
    "from gnn4itk_cf.stages.graph_construction.utils import handle_weighting\n",
    "from gnn4itk_cf.stages.graph_construction.models.utils import graph_intersection, build_edges\n",
    "from gnn4itk_cf.stages.graph_construction.utils import *\n",
    "\n",
    "from gnn4itk_cf.stages.track_building import utils \n",
    "from torch_geometric.utils import to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dr = \"../../examples/Example_1/data_reader.yaml\"\n",
    "config_mm = \"../../examples/Example_1/module_map_infer.yaml\"\n",
    "configGnn = \"../../examples/Example_1/gnn_infer.yaml\"\n",
    "configGnn_eval = \"../../examples/Example_1/gnn_eval.yaml\"\n",
    "config_tbi = \"../../examples/Example_1/track_building_infer.yaml\"\n",
    "config_tbe = \"../../examples/Example_1/track_building_eval.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#infer(config_dr )\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#infer(config_mm)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m infer(configGnn,\u001b[43mconfigGnn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifacts/best_3.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#evaluate(configGnn_eval,None)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#infer(config_tbi)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m evaluate(config_tbe,config_gnn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifacts/best_3.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "#infer(config_dr )\n",
    "#infer(config_mm)\n",
    "infer(configGnn,configGnn['stage_dir']+'artifacts/best_3.ckpt')\n",
    "#evaluate(configGnn_eval,None)\n",
    "#infer(config_tbi)\n",
    "evaluate(config_tbe,config_gnn['stage_dir']+'artifacts/best_3.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nlkawiib) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-thunder-6</strong> at: <a href='https://wandb.ai/gnnproject/CF_Example_1_GNN/runs/nlkawiib' target=\"_blank\">https://wandb.ai/gnnproject/CF_Example_1_GNN/runs/nlkawiib</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231208_145226-nlkawiib/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nlkawiib). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/global/homes/a/alazar/acorn/notebooks/inference/wandb/run-20231208_150127-hzg9v3wd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gnnproject/CF_Example_1_GNN/runs/hzg9v3wd' target=\"_blank\">dulcet-monkey-7</a></strong> to <a href='https://wandb.ai/gnnproject/CF_Example_1_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gnnproject/CF_Example_1_GNN' target=\"_blank\">https://wandb.ai/gnnproject/CF_Example_1_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gnnproject/CF_Example_1_GNN/runs/hzg9v3wd' target=\"_blank\">https://wandb.ai/gnnproject/CF_Example_1_GNN/runs/hzg9v3wd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/cf/Example_1/gnn/artifacts\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../examples/Example_2/metric_learning_train.yaml\", \"r\") as f:\n",
    "    config_ml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_ml = MetricLearning(config_ml)\n",
    "with open(\"../../examples/Example_1/gnn_train.yaml\", \"r\") as f:\n",
    "    config_gnn = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_gnn = InteractionGNN(config_gnn)\n",
    "\n",
    "run = wandb.init(project=model_gnn.hparams[\"project\"], entity='gnnproject')\n",
    "\n",
    "config_tbe = yaml.safe_load(open(\"../../examples/Example_1/track_building_eval.yaml\", \"r\"))\n",
    "print(config_gnn['stage_dir']+'artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.6 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../../scratch/cf/Example_2/metric_learning/artifacts/best.ckpt`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [particle_id] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [nhits] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [primary] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [pdgId] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [ghost] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [shared] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [module_id] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [region] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [hit_id] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n",
      "/global/homes/a/alazar/acorn/gnn4itk_cf/utils/loading_utils.py:78: UserWarning: OPTIONAL feature [pt] not found in data\n",
      "  warnings.warn(f\"OPTIONAL feature [{feature}] not found in data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining figures of merit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/alazar/acorn/gnn4itk_cf/stages/edge_classifier/edge_classifier_stage.py:94: UserWarning: Failed to define figures of merit, due to logger unavailable\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#model_ml.setup(stage=\"predict\")\n",
    "#dataloaders = model_ml.predict_dataloader()\n",
    "model_ml = MetricLearning.load_from_checkpoint(config_ml['stage_dir']+'artifacts/best.ckpt')\n",
    "model_gnn.setup('predict')\n",
    "dataloaders = model_gnn.predict_dataloader()\n",
    "model_gnn = InteractionGNN.load_from_checkpoint(config_gnn['stage_dir']+'artifacts/best-v3.ckpt')\n",
    "#model_gnn = InteractionGNN.load_from_checkpoint('../../model_store/Example_1/gnn.ckpt', config=config_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "infer() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#infer(config_dr )\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#infer(config_mm)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(config_gnn['stage_dir']+'artifacts/best_3.ckpt')\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigGnn\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/scratch/cf/Example_1/gnn/artifacts/best_3.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#evaluate(configGnn_eval,None)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#infer(config_tbi)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#evaluate(config_tbe,config_gnn['stage_dir']+'artifacts/best_3.ckpt')\u001b[39;00m\n\u001b[1;32m      9\u001b[0m evaluate(config_tbe, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m#,'../../model_store/Example_1/gnn.ckpt')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: infer() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "#infer(config_dr )\n",
    "#infer(config_mm)\n",
    "#print(config_gnn['stage_dir']+'artifacts/best_3.ckpt')\n",
    "infer(configGnn,'/scratch/cf/Example_1/gnn/artifacts/best_3.ckpt')\n",
    "#evaluate(configGnn_eval,None)\n",
    "#infer(config_tbi)\n",
    "#evaluate(config_tbe,config_gnn['stage_dir']+'artifacts/best_3.ckpt')\n",
    "\n",
    "evaluate(config_tbe, None) #,'../../model_store/Example_1/gnn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_labelled_graphs(graphset, config):\n",
    "    all_y_truth, all_pt  = [], []\n",
    "    evaluated_events = [\n",
    "        utils.evaluate_labelled_graph(\n",
    "            event,\n",
    "            matching_fraction=config[\"matching_fraction\"],\n",
    "            matching_style=config[\"matching_style\"],\n",
    "            min_track_length=config[\"min_track_length\"],\n",
    "            min_particle_length=config[\"min_particle_length\"],\n",
    "        )\n",
    "        for event in tqdm(graphset)\n",
    "    ]\n",
    "    evaluated_events = pd.concat(evaluated_events)\n",
    "\n",
    "    particles = evaluated_events[evaluated_events[\"is_reconstructable\"]]\n",
    "    reconstructed_particles = particles[particles[\"is_reconstructed\"] & particles[\"is_matchable\"]]\n",
    "    tracks = evaluated_events[evaluated_events[\"is_matchable\"]]\n",
    "    matched_tracks = tracks[tracks[\"is_matched\"]]\n",
    "\n",
    "    n_particles = len(particles.drop_duplicates(subset=['event_id', 'particle_id']))\n",
    "    n_reconstructed_particles = len(reconstructed_particles.drop_duplicates(subset=['event_id', 'particle_id']))\n",
    "\n",
    "    n_tracks = len(tracks.drop_duplicates(subset=['event_id', 'track_id']))\n",
    "    n_matched_tracks = len(matched_tracks.drop_duplicates(subset=['event_id', 'track_id']))\n",
    "\n",
    "    n_dup_reconstructed_particles = len(reconstructed_particles) - n_reconstructed_particles\n",
    "\n",
    "    print(f\"Number of reconstructed particles: {n_reconstructed_particles}\")\n",
    "    print(f\"Number of particles: {n_particles}\")\n",
    "    print(f\"Number of matched tracks: {n_matched_tracks}\")\n",
    "    print(f\"Number of tracks: {n_tracks}\")\n",
    "    print(f\"Number of duplicate reconstructed particles: {n_dup_reconstructed_particles}\")   \n",
    "\n",
    "    # Plot the results across pT and eta\n",
    "    eff = n_reconstructed_particles / n_particles\n",
    "    fake_rate = 1 - (n_matched_tracks / n_tracks)\n",
    "    dup_rate = n_dup_reconstructed_particles / n_reconstructed_particles\n",
    "\n",
    "    logging.info(f\"Efficiency: {eff:.3f}\")\n",
    "    logging.info(f\"Fake rate: {fake_rate:.3f}\")\n",
    "    logging.info(f\"Duplication rate: {dup_rate:.3f}\")\n",
    "    print(f\"Efficiency: {eff:.3f}\")\n",
    "    print(f\"Fake rate: {fake_rate:.3f}\")\n",
    "    print(f\"Duplication rate: {dup_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9999, device='cuda:0') tensor(3.4809e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5200e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5047e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5351e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5390e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5306e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5325e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.4633e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5302e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0') tensor(3.5531e-05, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reconstructed particles: 14613\n",
      "Number of particles: 16081\n",
      "Number of matched tracks: 16259\n",
      "Number of tracks: 16377\n",
      "Number of duplicate reconstructed particles: 1638\n",
      "Efficiency: 0.909\n",
      "Fake rate: 0.007\n",
      "Duplication rate: 0.112\n"
     ]
    }
   ],
   "source": [
    "device ='cuda'\n",
    "model_ml = model_ml.to(\"cuda\")\n",
    "model_gnn = model_gnn.to(\"cuda\")\n",
    "graphs = []\n",
    "for batch_idx, batch in enumerate(dataloaders[2]):\n",
    "    batch = batch.to(\"cuda\")    \n",
    "    gnn = model_gnn.shared_evaluation(batch,batch_idx)\n",
    "    #print(gnn['output'].max(),gnn['output'].min())\n",
    "    batch = gnn['batch']\n",
    "    #model_gnn.log_metrics(gnn['output'],gnn['all_truth'],gnn['target_truth'],gnn['loss'])\n",
    "    edge_mask = gnn['output'] > 0.8 #model_gnn.hparams['edge_cut'] # score_cut for evaluation\n",
    "    \n",
    "    # Get number of nodes\n",
    "    if hasattr(batch, \"num_nodes\"):\n",
    "        num_nodes = batch.num_nodes\n",
    "    elif hasattr(batch, \"x\"):\n",
    "        num_nodes = batch.x.size(0)\n",
    "    elif hasattr(batch, \"x_x\"):\n",
    "        num_nodes = batch.x_x.size(0)\n",
    "    else:\n",
    "        num_nodes = batch.edge_index.max().item() + 1\n",
    "    # Convert to sparse scipy array\n",
    "    sparse_edges = to_scipy_sparse_matrix(\n",
    "        batch.edge_index[:, edge_mask], num_nodes=num_nodes\n",
    "    )\n",
    "    # Run connected components\n",
    "    candidate_labels = sps.csgraph.connected_components(\n",
    "        sparse_edges, directed=False, return_labels=True\n",
    "    )\n",
    "    batch.labels = torch.from_numpy(candidate_labels[1]).long()\n",
    "    graphs.append(batch.to('cpu'))\n",
    "\n",
    "evaluate_labelled_graphs(graphs, config_tbe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
