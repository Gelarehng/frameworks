{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from itertools import chain, product, combinations\n",
    "import torch\n",
    "\n",
    "from time import time as tt\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from gnn4itk_cf.stages.data_reading.models.trackml_utils import *\n",
    "\n",
    "from gnn4itk_cf.stages.data_reading.data_reading_stage import EventReader\n",
    "from gnn4itk_cf.stages.data_reading.models.trackml_reader import TrackMLReader\n",
    "\n",
    "from gnn4itk_cf.stages.graph_construction.models.metric_learning import MetricLearning\n",
    "from gnn4itk_cf.stages.edge_classifier.models.filter import Filter\n",
    "from gnn4itk_cf.stages.edge_classifier import InteractionGNN\n",
    "\n",
    "from gnn4itk_cf.stages.graph_construction.utils import handle_weighting\n",
    "from gnn4itk_cf.stages.graph_construction.models.utils import graph_intersection, build_edges\n",
    "from gnn4itk_cf.stages.graph_construction.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"trackml_reader_config.yaml\"\n",
    "config = yaml.load(open(config_file, \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader = TrackMLReader.infer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_val=[93680], geta=[93680], weight=[93680], region=[93680], lx=[93680], lphi=[93680], module_index=[93680], x=[93680], r=[93680], gphi=[93680], hit_id=[93680], lz=[93680], z=[93680], cell_count=[93680], phi=[93680], y=[93680], ly=[93680], leta=[93680], eta=[93680], track_edges=[2, 68512], particle_id=[68512], radius=[68512], nhits=[68512], pt=[68512], config=[1], event_id='000001001')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"/workspaces/train100events/results/feature_store/trainset\"\n",
    "sample = torch.load(os.path.join(input_dir, \"event000001001-graph.pyg\"), map_location=\"cpu\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspaces/acorn/examples/Example_3/metric_learning_train.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_ML = MetricLearning(config)\n",
    "with open(\"/workspaces/acorn/examples/Example_3/filter_train.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_filter = Filter(config)\n",
    "with open(\"/workspaces/acorn/examples/Example_3/gnn_train.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_gnn = InteractionGNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 training events, 10 validation events and 10 testing events\n",
      "Defining figures of merit\n",
      "Defining figures of merit\n"
     ]
    }
   ],
   "source": [
    "model_ML.setup(stage=\"predict\")\n",
    "dataloaders = model_ML.predict_dataloader()\n",
    "#dataloaders[2].dataset.__dict__\n",
    "model_filter.setup('predict')\n",
    "model_gnn.setup('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0329, -0.0412, -0.1953,  ...,  0.4911,  0.4876,  0.4333],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.3679,  0.0570,  0.0410,  ..., -0.1526,  0.0040,  0.0806],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1463, -0.0067,  0.0218,  ...,  0.1621,  0.2134,  0.1807],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0312, -0.0760, -0.0247,  ...,  0.0831,  0.1865, -0.0918],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1532,  0.0218,  0.0165,  ..., -0.0594, -0.1280, -0.1287],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0107, 0.0271, 0.0598,  ..., 0.4425, 0.1881, 0.1814], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.2371,  0.1997,  0.1279,  ..., -0.3052,  0.0663,  0.0662],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0847, -0.0056,  0.0223,  ...,  0.4740,  0.4753,  0.2840],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1496, -0.0896, -0.0814,  ..., -0.0869, -0.0822,  0.1278],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0744, -0.0768, -0.1355,  ..., -0.1206, -0.0059,  0.1465],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "CPU times: user 10.8 s, sys: 575 ms, total: 11.3 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_ML = model_ML.to(\"cuda\")\n",
    "model_filter = model_filter.to(\"cuda\")\n",
    "model_gnn = model_gnn.to(\"cuda\")\n",
    "for batch in dataloaders[2]:\n",
    "    batch = batch.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embedding = model_ML.apply_embedding(batch)\n",
    "     \n",
    "    batch.edge_index = build_edges(\n",
    "        query=embedding, database=embedding, indices=None, r_max=0.1, k_max=10, backend=\"FRNN\"\n",
    "    )\n",
    "    R = batch.r**2 + batch.z**2\n",
    "    flip_edge_mask = R[batch.edge_index[0]] > R[batch.edge_index[1]]\n",
    "    batch.edge_index[:, flip_edge_mask] = batch.edge_index[:, flip_edge_mask].flip(0)\n",
    "    #out = model_filter(batch)   \n",
    "    #preds = torch.sigmoid(out) > 0.5\n",
    "    #update batch.edge_index\n",
    "    out = model_gnn(batch)\n",
    "    preds = torch.sigmoid(out) > 0.5\n",
    "    print(out)\n",
    "    sample=batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=sample.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_val': tensor([0.2916, 0.3245, 0.2921,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'geta': tensor([-2.0914, -1.4405, -2.0914,  ...,  0.0673,  0.0673,  0.0673],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'weight': tensor([1.8809e-05, 1.8770e-05, 2.7282e-05,  ..., 2.4526e-05, 1.6866e-05,\n",
       "         3.4333e-05], device='cuda:0', dtype=torch.float64),\n",
       " 'region': tensor([1., 1., 1.,  ..., 6., 6., 6.], device='cuda:0', dtype=torch.float64),\n",
       " 'lx': tensor([0.5000, 1.0000, 0.5000,  ..., 1.2000, 1.2000, 1.2000], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'lphi': tensor([0.8442, 0.8442, 0.8442,  ..., 1.5593, 1.5593, 1.5593], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'module_index': tensor([    0,     1,     2,  ..., 18717, 18718, 18726], device='cuda:0'),\n",
       " 'x': tensor([ -58.8380, -119.9720, -112.5270,  ..., -710.8110, -648.0540,\n",
       "         -802.9250], device='cuda:0', dtype=torch.float64),\n",
       " 'r': tensor([0.0597, 0.1200, 0.1149,  ..., 0.9317, 0.7760, 0.8081], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'gphi': tensor([-0.7441, -0.7544, -0.7250,  ...,  0.7767,  0.8092,  0.9760],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'hit_id': tensor([     7,     18,     25,  ..., 100332, 100334, 100366], device='cuda:0'),\n",
       " 'lz': tensor([3.0000, 3.0000, 3.0000,  ..., 7.0000, 7.0000, 7.0000], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'z': tensor([-1.5025, -1.5020, -1.4980,  ...,  2.9555,  2.9445,  2.9445],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'cell_count': tensor([1., 3., 1.,  ..., 1., 1., 1.], device='cuda:0', dtype=torch.float64),\n",
       " 'phi': tensor([-0.9465, -1.0001, -0.9356,  ...,  0.7766,  0.8150,  0.9643],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'y': tensor([-1.0072e+01, -1.4859e-01, -2.3244e+01,  ...,  6.0228e+02,\n",
       "          4.2688e+02,  9.1650e+01], device='cuda:0', dtype=torch.float64),\n",
       " 'ly': tensor([ 0.0563,  0.1125,  0.0563,  ..., 10.4000, 10.4000, 10.4000],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'leta': tensor([2.0914, 1.4405, 2.0914,  ..., 0.0673, 0.0673, 0.0673], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'eta': tensor([-3.9192, -3.2220, -3.2624,  ...,  1.8716,  2.0436,  2.0044],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " 'track_edges': tensor([[    2,     3,     5,  ..., 11883, 11888, 11891],\n",
       "         [    7,     8,     0,  ..., 11885, 11890, 11892]], device='cuda:0'),\n",
       " 'particle_id': tensor([526922324633452544, 499910897351786496, 675543792396271616,\n",
       "          ..., 459368605100802048, 360290993846616064,\n",
       "         585474892225314816], device='cuda:0'),\n",
       " 'radius': tensor([0.0064, 0.0085, 0.0021,  ..., 0.0207, 0.0139, 0.0352], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'nhits': tensor([11., 13., 11.,  ..., 15., 11., 11.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'pt': tensor([1.7875, 1.4256, 1.0177,  ..., 1.0486, 1.5454, 1.0461], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'config': [[{'stage': 'data_reading',\n",
       "    'model': 'TrackMLReader',\n",
       "    'input_dir': '/workspace/train_100_events',\n",
       "    'stage_dir': '/workspace/train_100_events/results/feature_store/',\n",
       "    'detector_path': '/workspace/train_100_events/detectors.csv',\n",
       "    'max_workers': 32,\n",
       "    'feature_sets': {'hit_features': ['hit_id',\n",
       "      'x',\n",
       "      'y',\n",
       "      'z',\n",
       "      'r',\n",
       "      'phi',\n",
       "      'eta',\n",
       "      'region',\n",
       "      'module_index',\n",
       "      'weight',\n",
       "      'cell_count',\n",
       "      'cell_val',\n",
       "      'leta',\n",
       "      'lphi',\n",
       "      'lx',\n",
       "      'ly',\n",
       "      'lz',\n",
       "      'geta',\n",
       "      'gphi'],\n",
       "     'track_features': ['particle_id', 'pt', 'radius', 'nhits']},\n",
       "    'module_columns': ['volume_id', 'layer_id', 'module_id'],\n",
       "    'region_labels': {1: {'volume_id': 7},\n",
       "     2: {'volume_id': [12, 16]},\n",
       "     3: {'volume_id': 8},\n",
       "     4: {'volume_id': [13, 17]},\n",
       "     5: {'volume_id': 9},\n",
       "     6: {'volume_id': [14, 18]}}}]],\n",
       " 'event_id': ['000001098'],\n",
       " 'num_nodes': tensor(11896, device='cuda:0'),\n",
       " 'batch': tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'),\n",
       " 'ptr': tensor([    0, 11896], device='cuda:0'),\n",
       " 'edge_index': tensor([[    2,     3,     5,  ..., 11852, 11853, 11895],\n",
       "         [    0,     0,     0,  ..., 11895, 11895, 11882]], device='cuda:0'),\n",
       " '_num_nodes': [tensor(11896)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/acorn/notebooks/inference1.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32302e30345c5c686f6d655c5c616c696e616c5c5c70726f6a656374735c5c61636f726e222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f616c696e616c2f70726f6a656374732f61636f726e2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/acorn/notebooks/inference1.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m export_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(model_filter, sample,\u001b[39m\"\u001b[39;49m\u001b[39mfilter.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     _export(\n\u001b[1;32m    517\u001b[0m         model,\n\u001b[1;32m    518\u001b[0m         args,\n\u001b[1;32m    519\u001b[0m         f,\n\u001b[1;32m    520\u001b[0m         export_params,\n\u001b[1;32m    521\u001b[0m         verbose,\n\u001b[1;32m    522\u001b[0m         training,\n\u001b[1;32m    523\u001b[0m         input_names,\n\u001b[1;32m    524\u001b[0m         output_names,\n\u001b[1;32m    525\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    526\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    527\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    528\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    529\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    530\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    531\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    532\u001b[0m         autograd_inlining\u001b[39m=\u001b[39;49mautograd_inlining,\n\u001b[1;32m    533\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1596\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1594\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1596\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1597\u001b[0m     model,\n\u001b[1;32m   1598\u001b[0m     args,\n\u001b[1;32m   1599\u001b[0m     verbose,\n\u001b[1;32m   1600\u001b[0m     input_names,\n\u001b[1;32m   1601\u001b[0m     output_names,\n\u001b[1;32m   1602\u001b[0m     operator_export_type,\n\u001b[1;32m   1603\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1604\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1605\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1606\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1607\u001b[0m )\n\u001b[1;32m   1609\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1611\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1612\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[39m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args)\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, params, torch_out, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[39m=\u001b[39m _trace_and_get_graph_from_model(model, args)\n\u001b[1;32m   1012\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_get_trace_graph(\n\u001b[1;32m    916\u001b[0m     model,\n\u001b[1;32m    917\u001b[0m     args,\n\u001b[1;32m    918\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    919\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    920\u001b[0m     _return_inputs_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    921\u001b[0m )\n\u001b[1;32m    922\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:1285\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1284\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[0;32m-> 1285\u001b[0m outs \u001b[39m=\u001b[39m ONNXTracedModule(\n\u001b[1;32m   1286\u001b[0m     f, strict, _force_outplace, return_inputs, _return_inputs_states\n\u001b[1;32m   1287\u001b[0m )(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1288\u001b[0m \u001b[39mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:133\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 133\u001b[0m graph, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_graph_by_tracing(\n\u001b[1;32m    134\u001b[0m     wrapper,\n\u001b[1;32m    135\u001b[0m     in_vars \u001b[39m+\u001b[39;49m module_state,\n\u001b[1;32m    136\u001b[0m     _create_interpreter_name_lookup_fn(),\n\u001b[1;32m    137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrict,\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_force_outplace,\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs:\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, outs[\u001b[39m0\u001b[39m], ret_inputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:124\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    123\u001b[0m     inputs_states\u001b[39m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 124\u001b[0m outs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(\u001b[39m*\u001b[39;49mtrace_inputs))\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    126\u001b[0m     inputs_states[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (inputs_states[\u001b[39m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1508\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1508\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1509\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1510\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/gnn4itk_cf/stages/edge_classifier/models/filter.py:53\u001b[0m, in \u001b[0;36mFilter.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m     52\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(\n\u001b[0;32m---> 53\u001b[0m         [batch[feature] \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mnode_features\u001b[39m\u001b[39m\"\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     54\u001b[0m     )\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     55\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(\n\u001b[1;32m     56\u001b[0m         torch\u001b[39m.\u001b[39mcat([x[batch\u001b[39m.\u001b[39medge_index[\u001b[39m0\u001b[39m]], x[batch\u001b[39m.\u001b[39medge_index[\u001b[39m1\u001b[39m]]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/gnn4itk_cf/stages/edge_classifier/models/filter.py:53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m     52\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(\n\u001b[0;32m---> 53\u001b[0m         [batch[feature] \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mnode_features\u001b[39m\u001b[39m\"\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     54\u001b[0m     )\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     55\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(\n\u001b[1;32m     56\u001b[0m         torch\u001b[39m.\u001b[39mcat([x[batch\u001b[39m.\u001b[39medge_index[\u001b[39m0\u001b[39m]], x[batch\u001b[39m.\u001b[39medge_index[\u001b[39m1\u001b[39m]]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "export_output = torch.onnx.export(model_filter, sample,\"filter.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Positives\n",
    "# edge_positive = preds.sum().float()\n",
    "\n",
    "# # Signal true & signal tp\n",
    "# sig_true = outputs[\"target_truth\"].sum().float()\n",
    "# sig_true_positive = (outputs[\"target_truth\"].bool() & preds).sum().float()\n",
    "# background_true_positive = (outputs[\"all_truth\"].bool() & preds).sum().float()\n",
    "# sig_eff = sig_true_positive / sig_true\n",
    "# sig_pur = sig_true_positive / edge_positive\n",
    "# background_pur = background_true_positive / edge_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frnn import _C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
